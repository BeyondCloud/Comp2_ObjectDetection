{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID\n",
    "    106061514 許鈞棠  106061536 廖學煒\n",
    "# Result\n",
    "## ( 10~20 epochs / 200 epochs/ 1000 epochs)\n",
    "\n",
    "<img src=\"./img/cat123.jpg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "## testing set: 1000epochs\n",
    "\n",
    "<img src=\"./img/men.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "    \n",
    "# What kind of models you have tried and how did they work.\n",
    "    1. Mask RCNN:\n",
    "   __https://github.com/matterport/Mask_RCNN__<br>\n",
    "        # The model outputs both the bounding boxes and the segmentaion region of the objects\n",
    "        >high accuracy\n",
    "        Problems:\n",
    "        1.The backbone model depends on the pretrain models RESNET_50/101, which is not allowed in the \n",
    "        competition unless we train it from scratch. In consideration of our two weeks time limitation, \n",
    "        this approach seems to be infeasible.\n",
    "        2.The code of train + model is huge (more than 4000 line), which is hard to trace and debug.\n",
    "        I give up this model for the sake of time limitation.\n",
    "    2. Yolo tiny net:\n",
    "         Advantage:\n",
    "         >train fast , low memory usage, code is similar to the course slide except the model part\n",
    "         Problems:\n",
    "         The model reach the bottle neck after 12 hours of training\n",
    "         > It could barely pass benchmark 60 in our competition\n",
    "    2. Yolo net:\n",
    "         Advantage:\n",
    "         > good accuracy (slightly inferior to RCNN)\n",
    "         > The loss function is already provided by TA\n",
    "         > The model strike a balance between performance ,training time and memory usage\n",
    "         > Fast prediction speed : about 60X faster than RCNN which saves alot of time of running test image \n",
    "         > The model requires only 4G GPU memory while training on small batch size (16)\n",
    "         > No backbone model required\n",
    "         Potential problem:\n",
    "         Training might take a long time (according to the paper, they pretrain their model on coco net and take about \n",
    "         one week to reach marvelous result). \n",
    "        After 2-3 days of training, this model passed benchmark 80 in this comepitition \n",
    "# Anything you've done and want to tell us.\n",
    "    Prediction thresholding\n",
    "        >If the classification accuracy isn't high enough, the best choose of confidence score will fall at 0.1~0.2.\n",
    "        After the accuracy is high enough (after 3~5 days training), I'll set the threshold to zero to reach the highest\n",
    "        mAP.\n",
    "    Hardware:\n",
    "        1080 Ti 11G ram\n",
    "    Training Epochs:\n",
    "        About 1000~1500 will give nice result\n",
    "    Preprocessing:\n",
    "        Normalize pixel value to -1~1 by calculating pixel/ 255.0 * 2 - 1\n",
    "        resize to 448x448\n",
    "# What problems you occured and how did you solve them.\n",
    "    1.Importance of initial variable choosing\n",
    "        Frankly speaking, the yolo model performs miserably (mAP<0.05) on my first attempt of training.\n",
    "        After few days of debugging and code reading, I found that some output neurons has already died \n",
    "        and the gradient only come from other neurons with large output value.\n",
    "        \n",
    "        In the initial stage of training, the prediction width and height were ridiculously huge( > 1e16).\n",
    "        As far as I'm concerned, this is the most crucial trap while training the yolo net:\n",
    "        > large prediction output is tantamount to large x,y,w,h predict value. Providing that the prediction bounding\n",
    "        boxes' size and position are far away from the ground truths, the iou could always be zero.\n",
    "        Since the class loss and object/non object loss depends on the iou confidence score, the model is impossible\n",
    "        to improve if iou is always zero.\n",
    "        \n",
    "        Consequently, I deleted my fine-tuned trash model and carefully chose the initial variables\n",
    "        of the neurons. Surprisingly, the model converge pretty fast if the initial variable is chosen properly.\n",
    "        In this case, I used truncate norm (mean = 0, std = 0.05) to generate the initial variable and set the bias\n",
    "        to all zeros.\n",
    "        A proper size of initial variable could save your model alot of time to converge and even provides your model \n",
    "        from gradient exxplosion\n",
    "    2. Switch from SGD optimizer to Adam \n",
    "        Tensorflow might report that some variables not found while restoring the model so you're not able to load it.\n",
    "        In this case, you have to initialize uninitialized variables.\n",
    "        See TrainModel code's initialize_uninitialized_vars() function for more details and the example code below to\n",
    "        find out how it works.\n",
    "    3.Experiment: COCO dataset\n",
    "        I attempted to use COCO dataset to train my model. However, I misunderstood that this dataset has only one\n",
    "        bounding box for each image (after competition I found that they separate each bounding box of single image\n",
    "        into different json cells)\n",
    "        So I used a \"defective\" dataset to train my model and the result is horrible.\n",
    "        After 5 hours of training with the coco dataset inserted, my model predicts a lots of \"person\" class. This \n",
    "        shows that the dataset without highlighting all objects could lead to undesirable result.\n",
    "        Anyway, my model is enough to go on with the competition even COCO dataset is not applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# python tools/YOLO_small_tf.py -c conf/train_small.cfg\n",
    "ver = 14000\n",
    "my_pretrain_path = './models/train/new'+str(ver)+'.ckpt'\n",
    "\n",
    "is_save = True\n",
    "save_name = '/new'+str(ver+1000)+'.ckpt'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "sys.path.append('./')\n",
    "\n",
    "import yolo\n",
    "from yolo.utils.process_config import process_config\n",
    "from optparse import OptionParser\n",
    "        \n",
    "\n",
    "class YOLO_TF:\n",
    "    debug = []\n",
    "    fromfile = None\n",
    "    tofile_img = 'test/output.jpg'\n",
    "    tofile_txt = 'test/output.txt'\n",
    "    imshow = True\n",
    "    filewrite_img = False\n",
    "    filewrite_txt = False\n",
    "    disp_console = True\n",
    "    # weights_file = './models/train/model_small.ckpt'\n",
    "    weights_file =  None\n",
    "    \n",
    "    alpha = 0.1\n",
    "    threshold = 0.02 #confidence thres\n",
    "    iou_threshold = 0.5\n",
    "    num_class = 20\n",
    "    num_box = 2\n",
    "    grid_size = 7\n",
    "    classes =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "\n",
    "    w_img = 640\n",
    "    h_img = 480\n",
    "\n",
    "    def __init__(self,argvs = []):\n",
    "        # self.argv_parser(argvs)\n",
    "\n",
    "        parser = OptionParser()\n",
    "        parser.add_option(\"-c\", \"--conf\", dest=\"configure\",  \n",
    "                          help=\"configure filename\")\n",
    "        (options, args) = parser.parse_args() \n",
    "        if options.configure:\n",
    "          conf_file = str(options.configure)\n",
    "          print('config loaded')\n",
    "        else:\n",
    "          print('please specify --conf configure filename')\n",
    "          exit(0)\n",
    "        self.common_params, self.dataset_params,self.net_params, self.solver_params = process_config(conf_file)\n",
    "        print(self.common_params)\n",
    "        print(self.dataset_params)\n",
    "        print(self.net_params)\n",
    "        print(self.solver_params)\n",
    "        self.image_size = int(self.common_params['image_size'])\n",
    "        self.batch_size = int(self.common_params['batch_size'])\n",
    "        self.cell_size = int(self.net_params['cell_size'])\n",
    "        self.boxes_per_cell = int(self.net_params['boxes_per_cell'])\n",
    "        self.num_classes = int(self.common_params['num_classes'])\n",
    "        self.object_scale = float(self.net_params['object_scale'])\n",
    "        self.noobject_scale = float(self.net_params['noobject_scale'])\n",
    "        self.class_scale = float(self.net_params['class_scale'])\n",
    "        self.coord_scale = float(self.net_params['coord_scale'])\n",
    "        self.max_objects = int(self.common_params['max_objects_per_image'])\n",
    "        self.max_iterators = int(self.solver_params['max_iterators'])\n",
    "        self.learning_rate = float(self.solver_params['learning_rate'])\n",
    "        self.moment = float(self.solver_params['moment'])\n",
    "        self.train_dir = self.solver_params['train_dir']\n",
    "        self.pretrain_path = my_pretrain_path\n",
    "        self.build_networks()\n",
    "        # self.fromfile ='./cat.jpg'\n",
    "        if self.fromfile is not None: self.detect_from_file(self.fromfile)\n",
    "\n",
    "    def initialize_uninitialized_vars(self,sess):\n",
    "        from itertools import compress\n",
    "        global_vars = tf.global_variables()\n",
    "        is_not_initialized = sess.run([~(tf.is_variable_initialized(var)) \\\n",
    "                                       for var in global_vars])\n",
    "        not_initialized_vars = list(compress(global_vars, is_not_initialized))\n",
    "\n",
    "        if len(not_initialized_vars):\n",
    "            sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "    def build_networks(self):\n",
    "        if self.disp_console : print(\"Building YOLO_small graph...\")\n",
    "        self.x = tf.placeholder('float32',[None,448,448,3])\n",
    "        self.labels = tf.placeholder(tf.float32, (self.batch_size, self.max_objects, 5))\n",
    "        self.objects_num = tf.placeholder(tf.int32, (self.batch_size))\n",
    "        # self.schedule_lr = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.conv_1 = self.conv_layer(1,self.x,64,7,2)\n",
    "        self.pool_2 = self.pooling_layer(2,self.conv_1,2,2)\n",
    "        self.conv_3 = self.conv_layer(3,self.pool_2,192,3,1)\n",
    "        self.pool_4 = self.pooling_layer(4,self.conv_3,2,2)\n",
    "        self.conv_5 = self.conv_layer(5,self.pool_4,128,1,1)\n",
    "        self.conv_6 = self.conv_layer(6,self.conv_5,256,3,1)\n",
    "        self.conv_7 = self.conv_layer(7,self.conv_6,256,1,1)\n",
    "        self.conv_8 = self.conv_layer(8,self.conv_7,512,3,1)\n",
    "        self.pool_9 = self.pooling_layer(9,self.conv_8,2,2)\n",
    "        self.conv_10 = self.conv_layer(10,self.pool_9,256,1,1)\n",
    "        self.conv_11 = self.conv_layer(11,self.conv_10,512,3,1)\n",
    "        self.conv_12 = self.conv_layer(12,self.conv_11,256,1,1)\n",
    "        self.conv_13 = self.conv_layer(13,self.conv_12,512,3,1)\n",
    "        self.conv_14 = self.conv_layer(14,self.conv_13,256,1,1)\n",
    "        self.conv_15 = self.conv_layer(15,self.conv_14,512,3,1)\n",
    "        self.conv_16 = self.conv_layer(16,self.conv_15,256,1,1)\n",
    "        self.conv_17 = self.conv_layer(17,self.conv_16,512,3,1)\n",
    "        self.conv_18 = self.conv_layer(18,self.conv_17,512,1,1)\n",
    "        self.conv_19 = self.conv_layer(19,self.conv_18,1024,3,1)\n",
    "        self.pool_20 = self.pooling_layer(20,self.conv_19,2,2)\n",
    "        self.conv_21 = self.conv_layer(21,self.pool_20,512,1,1)\n",
    "        self.conv_22 = self.conv_layer(22,self.conv_21,1024,3,1)\n",
    "        self.conv_23 = self.conv_layer(23,self.conv_22,512,1,1)\n",
    "        self.conv_24 = self.conv_layer(24,self.conv_23,1024,3,1)\n",
    "        self.conv_25 = self.conv_layer(25,self.conv_24,1024,3,1)\n",
    "        self.conv_26 = self.conv_layer(26,self.conv_25,1024,3,2)\n",
    "        self.conv_27 = self.conv_layer(27,self.conv_26,1024,3,1)\n",
    "        self.conv_28 = self.conv_layer(28,self.conv_27,1024,3,1)\n",
    "        self.fc_29 = self.fc_layer(29,self.conv_28,512,flat=True,linear=False)\n",
    "\n",
    "        self.fc_30 = self.fc_layer(30,self.fc_29,4096,flat=False,linear=False)\n",
    "        #skip dropout_31\n",
    "        self.fc_32 = self.fc_layer(32,self.fc_30,1470,flat=False,linear=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        n1 = self.cell_size * self.cell_size * self.num_classes\n",
    "        n2 = n1 + self.cell_size * self.cell_size * self.boxes_per_cell\n",
    "        class_probs = tf.reshape(self.fc_32[:, 0:n1], (-1, 7,7,20))\n",
    "        scales = tf.reshape(self.fc_32[:, n1:n2], (-1, 7,7,2))\n",
    "        boxes = tf.reshape(self.fc_32[:, n2:], (-1,7, 7, 2*4))\n",
    "\n",
    "        self.predicts   = tf.concat([class_probs, scales, boxes], 3)\n",
    "\n",
    "\n",
    "        # predicts = self.interpret_output(self.fc_32[0])\n",
    "        self.loss,self.debug = self.yolo_loss(self.predicts ,self.labels,self.objects_num)\n",
    "\n",
    "\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "        self.sess = tf.Session(config = config)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate, self.moment,epsilon = 1.0)\n",
    "        \n",
    "        # optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "        \n",
    "        # optimizer = tf.train.GradientDescentOptimizer(self.schedule_lr)\n",
    "        self.train_op = optimizer.minimize(self.loss)\n",
    "\n",
    "        self.sess.run( tf.global_variables_initializer())\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        self.saver.restore(self.sess, self.pretrain_path)\n",
    "\n",
    "        \n",
    "        # self.initialize_uninitialized_vars(self.sess)\n",
    "        \n",
    "\n",
    "\n",
    "    def conv_layer(self,idx,inputs,filters,size,stride):\n",
    "        channels = inputs.get_shape()[3]\n",
    "        weight = tf.Variable(tf.truncated_normal([size,size,int(channels),filters],mean = 0.0000,stddev=0.05))\n",
    "        biases = tf.Variable(tf.constant(0.000, shape=[filters]))\n",
    "\n",
    "        pad_size = size//2\n",
    "        pad_mat = np.array([[0,0],[pad_size,pad_size],[pad_size,pad_size],[0,0]])\n",
    "        inputs_pad = tf.pad(inputs,pad_mat)\n",
    "\n",
    "        conv = tf.nn.conv2d(inputs_pad, weight, strides=[1, stride, stride, 1], padding='VALID',name=str(idx)+'_conv')  \n",
    "        conv_biased = tf.add(conv,biases,name=str(idx)+'_conv_biased')  \n",
    "        if self.disp_console : print('    Layer  %d : Type = Conv, Size = %d * %d, Stride = %d, Filters = %d, Input channels = %d' % (idx,size,size,stride,filters,int(channels)))\n",
    "        return tf.maximum(self.alpha*conv_biased,conv_biased,name=str(idx)+'_leaky_relu')\n",
    "\n",
    "    def pooling_layer(self,idx,inputs,size,stride):\n",
    "        if self.disp_console : print('    Layer  %d : Type = Pool, Size = %d * %d, Stride = %d' % (idx,size,size,stride))\n",
    "        return tf.nn.max_pool(inputs, ksize=[1, size, size, 1],strides=[1, stride, stride, 1], padding='SAME',name=str(idx)+'_pool')\n",
    "\n",
    "    def fc_layer(self,idx,inputs,hiddens,flat = False,linear = False):\n",
    "        input_shape = inputs.get_shape().as_list()      \n",
    "        if flat:\n",
    "            dim = input_shape[1]*input_shape[2]*input_shape[3]\n",
    "            inputs_transposed = tf.transpose(inputs,(0,3,1,2))\n",
    "            inputs_processed = tf.reshape(inputs_transposed, [-1,dim])\n",
    "        else:\n",
    "            dim = input_shape[1]\n",
    "            inputs_processed = inputs\n",
    "        weight = tf.Variable(tf.truncated_normal([dim,hiddens],mean = 0.000, stddev=0.01))\n",
    "        biases = tf.Variable(tf.constant(0.00, shape=[hiddens])) \n",
    "        if self.disp_console : print('    Layer  %d : Type = Full, Hidden = %d, Input dimension = %d, Flat = %d, Activation = %d' % (idx,hiddens,int(dim),int(flat),1-int(linear)))\n",
    "        if linear : return tf.add(tf.matmul(inputs_processed,weight),biases,name=str(idx)+'_fc')\n",
    "        ip = tf.add(tf.matmul(inputs_processed,weight),biases)\n",
    "\n",
    "\n",
    "        return tf.maximum(self.alpha*ip,ip,name=str(idx)+'_fc')\n",
    "    def training(self): #TODO add training function!\n",
    "\n",
    "        print(' model exist:',self.pretrain_path)\n",
    "        # except:print('model not found')\n",
    "        print('dataset loaded')\n",
    "\n",
    "\n",
    "        dataset = eval(self.dataset_params['name'])(self.common_params, self.dataset_params)\n",
    "\n",
    "        \n",
    "        # np_images, np_labels, np_objects_num = dataset.batch()\n",
    "        # print(np_labels)\n",
    "        for step in range(1,self.max_iterators):\n",
    "            start_time = time.time()\n",
    "            np_images, np_labels, np_objects_num = dataset.batch()\n",
    "\n",
    "\n",
    "            _,loss_value,debug = self.sess.run([self.train_op,self.loss,self.debug],feed_dict={self.x: np_images,\n",
    "                                                                            self.labels:np_labels,\n",
    "                                                                            self.objects_num:np_objects_num})\n",
    "            # print(debug)\n",
    "            duration = time.time() - start_time\n",
    "            assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                num_examples_per_step = self.batch_size\n",
    "                examples_per_sec = num_examples_per_step / duration\n",
    "                sec_per_batch = float(duration)\n",
    "\n",
    "                format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                              'sec/batch)')\n",
    "                print(debug)\n",
    "                print (format_str % (datetime.now(), step, loss_value,\n",
    "                                     examples_per_sec, sec_per_batch))\n",
    "\n",
    "            sys.stdout.flush()\n",
    "            if step % 1200 == 0:\n",
    "                if is_save:\n",
    "                    self.saver.save(self.sess, self.train_dir + save_name)\n",
    "                    print('save to',save_name)\n",
    "\n",
    "\n",
    "\n",
    "        #calculate loss\n",
    "    def yolo_loss(self, predicts, labels, objects_num):\n",
    "        \"\"\"\n",
    "        calculate loss\n",
    "        Args:\n",
    "          predict: 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\n",
    "          labels : [max_objects, 5]  (x_center, y_center, w, h, class)\n",
    "        \"\"\"\n",
    "        \"\"\"Add Loss to all the trainable variables\n",
    "          Args:\n",
    "          predicts: 4-D tensor [batch_size, cell_size, cell_size, 5 * boxes_per_cell]\n",
    "          ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n",
    "          labels  : 3-D tensor of [batch_size, max_objects, 5]\n",
    "          objects_num: 1-D tensor [batch_size]\n",
    "        \"\"\"\n",
    "        def condition(num, object_num, loss, predict, label, nilboy):\n",
    "            \"\"\"\n",
    "            if num < object_num\n",
    "            \"\"\"\n",
    "            return num < object_num\n",
    "        \n",
    "        class_loss = tf.constant(0, tf.float32)\n",
    "        object_loss = tf.constant(0, tf.float32)\n",
    "        noobject_loss = tf.constant(0, tf.float32)\n",
    "        coord_loss = tf.constant(0, tf.float32)\n",
    "        loss = [0, 0, 0, 0]\n",
    "        for i in range(self.batch_size):\n",
    "            predict = predicts[i, :, :, :]\n",
    "            label = labels[i, :, :]\n",
    "            object_num = objects_num[i]\n",
    "\n",
    "            nilboy = tf.ones([7,7,2])\n",
    "            # nilboy = tf.ones([])\n",
    "            \n",
    "            tuple_results = tf.while_loop(condition, self.losses_calculation, \n",
    "                                          [tf.constant(0), object_num, \n",
    "                                           [class_loss, object_loss, noobject_loss, coord_loss], \n",
    "                                           predict, label, nilboy])\n",
    "\n",
    "            for j in range(4):\n",
    "                loss[j] = loss[j] + tuple_results[2][j]\n",
    "            # nilboy = tuple_results[5]\n",
    "\n",
    "        tf.add_to_collection('losses', (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size)\n",
    "\n",
    "        tf.summary.scalar('class_loss', loss[0]/self.batch_size)\n",
    "        tf.summary.scalar('object_loss', loss[1]/self.batch_size)\n",
    "        tf.summary.scalar('noobject_loss', loss[2]/self.batch_size)\n",
    "        tf.summary.scalar('coord_loss', loss[3]/self.batch_size)\n",
    "        tf.summary.scalar('weight_loss', tf.add_n(tf.get_collection('losses')) \n",
    "                          - (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size )\n",
    "\n",
    "        nilboy = loss\n",
    "        return tf.add_n(tf.get_collection('losses'), name='total_loss'), nilboy\n",
    "    def losses_calculation(self, num, object_num, loss, predict, labels, nilboy):\n",
    "        \"\"\"\n",
    "        calculate loss\n",
    "        Args:\n",
    "          predict: 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\n",
    "          labels : [max_objects, 5]  (x_center, y_center, w, h, class)\n",
    "        \"\"\"\n",
    "        label = labels[num:num+1, :]\n",
    "        label = tf.reshape(label, [-1])\n",
    "\n",
    "        #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "        min_x = (label[0] - label[2] / 2) / (self.image_size / self.cell_size)\n",
    "        max_x = (label[0] + label[2] / 2) / (self.image_size / self.cell_size)\n",
    "\n",
    "        min_y = (label[1] - label[3] / 2) / (self.image_size / self.cell_size)\n",
    "        max_y = (label[1] + label[3] / 2) / (self.image_size / self.cell_size)\n",
    "\n",
    "        min_x = tf.floor(min_x)\n",
    "        min_y = tf.floor(min_y)\n",
    "\n",
    "        max_x = tf.minimum(tf.ceil(max_x), self.cell_size)\n",
    "        max_y = tf.minimum(tf.ceil(max_y), self.cell_size)\n",
    "\n",
    "        temp = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\n",
    "        objects = tf.ones(temp, tf.float32)\n",
    "\n",
    "        temp = tf.cast(tf.stack([min_y, self.cell_size - max_y, min_x, self.cell_size - max_x]), tf.int32)\n",
    "        temp = tf.reshape(temp, (2, 2))\n",
    "        objects = tf.pad(objects, temp, \"CONSTANT\")\n",
    "\n",
    "        #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "        #calculate responsible tensor [CELL_SIZE, CELL_SIZE]\n",
    "        center_x = label[0] / (self.image_size / self.cell_size)\n",
    "        center_x = tf.floor(center_x)\n",
    "\n",
    "        center_y = label[1] / (self.image_size / self.cell_size)\n",
    "        center_y = tf.floor(center_y)\n",
    "\n",
    "        response = tf.ones([1, 1], tf.float32)\n",
    "\n",
    "        temp = tf.cast(tf.stack([center_y, self.cell_size - center_y - 1, \n",
    "                                 center_x, self.cell_size -center_x - 1]), \n",
    "                       tf.int32)\n",
    "        self.tmp = tf.stack([center_y, self.cell_size - center_y - 1, \n",
    "                             center_x, self.cell_size -center_x - 1])\n",
    "        temp = tf.reshape(temp, (2, 2))\n",
    "        response = tf.pad(response, temp, \"CONSTANT\")\n",
    "        #objects = response\n",
    "\n",
    "        #calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        predict_boxes = predict[:, :, self.num_classes + self.boxes_per_cell:]\n",
    "\n",
    "        predict_boxes = tf.reshape(predict_boxes, [self.cell_size, \n",
    "                                                   self.cell_size, \n",
    "                                                   self.boxes_per_cell, 4])\n",
    "\n",
    "        predict_boxes = predict_boxes * [self.image_size / self.cell_size, \n",
    "                                         self.image_size / self.cell_size, \n",
    "                                         self.image_size, self.image_size]\n",
    "\n",
    "        base_boxes = np.zeros([self.cell_size, self.cell_size, 4])\n",
    "\n",
    "        #for each cell\n",
    "        for y in range(self.cell_size):\n",
    "            for x in range(self.cell_size):\n",
    "                \n",
    "                base_boxes[y, x, :] = [self.image_size / self.cell_size * x, self.image_size / self.cell_size * y, 0, 0]\n",
    "                \n",
    "        base_boxes = np.tile(np.resize(base_boxes, [self.cell_size, self.cell_size, 1, 4]), [1, 1, self.boxes_per_cell, 1])\n",
    "\n",
    "        #if there's no predict_box in that cell, then the base_boxes will be calcuated with label and got iou equals 0\n",
    "        predict_boxes = base_boxes + predict_boxes\n",
    "\n",
    "        iou_predict_truth = self.iou(predict_boxes, label[0:4])\n",
    "        #calculate C [cell_size, cell_size, boxes_per_cell]\n",
    "        C = iou_predict_truth * tf.reshape(response, [self.cell_size, self.cell_size, 1])\n",
    "\n",
    "        #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        I = iou_predict_truth * tf.reshape(response, (self.cell_size, self.cell_size, 1))\n",
    "\n",
    "        max_I = tf.reduce_max(I, 2, keep_dims=True)\n",
    "\n",
    "        I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (self.cell_size, self.cell_size, 1))\n",
    "\n",
    "        #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        no_I = tf.ones_like(I, dtype=tf.float32) - I \n",
    "\n",
    "\n",
    "        p_C = predict[:, :, self.num_classes:self.num_classes + self.boxes_per_cell]\n",
    "\n",
    "        #calculate truth x, y, sqrt_w, sqrt_h 0-D\n",
    "        x = label[0]\n",
    "        y = label[1]\n",
    "\n",
    "        sqrt_w = tf.sqrt(tf.abs(label[2]))\n",
    "        sqrt_h = tf.sqrt(tf.abs(label[3]))\n",
    "\n",
    "        #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        p_x = predict_boxes[:, :, :, 0]\n",
    "        p_y = predict_boxes[:, :, :, 1]\n",
    "\n",
    "        #p_sqrt_w = tf.sqrt(tf.abs(predict_boxes[:, :, :, 2])) * ((tf.cast(predict_boxes[:, :, :, 2] > 0, tf.float32) * 2) - 1)\n",
    "        #p_sqrt_h = tf.sqrt(tf.abs(predict_boxes[:, :, :, 3])) * ((tf.cast(predict_boxes[:, :, :, 3] > 0, tf.float32) * 2) - 1)\n",
    "        #p_sqrt_w = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 2]))\n",
    "        #p_sqrt_h = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 3]))\n",
    "        #p_sqrt_w = predict_boxes[:, :, :, 2]\n",
    "        #p_sqrt_h = predict_boxes[:, :, :, 3]\n",
    "        p_sqrt_w = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "        p_sqrt_h = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "        \n",
    "        #calculate truth p 1-D tensor [NUM_CLASSES]\n",
    "        P = tf.one_hot(tf.cast(label[4], tf.int32), self.num_classes, dtype=tf.float32)\n",
    "\n",
    "        #calculate predict p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\n",
    "        p_P = predict[:, :, 0:self.num_classes]\n",
    "\n",
    "        #class_loss\n",
    "        class_loss = tf.nn.l2_loss(tf.reshape(objects, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\n",
    "        #class_loss = tf.nn.l2_loss(tf.reshape(response, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\n",
    "\n",
    "        #object_loss\n",
    "        object_loss = tf.nn.l2_loss(I * (p_C - C)) * self.object_scale\n",
    "        #object_loss = tf.nn.l2_loss(I * (p_C - (C + 1.0)/2.0)) * self.object_scale\n",
    "\n",
    "        #noobject_loss\n",
    "        #noobject_loss = tf.nn.l2_loss(no_I * (p_C - C)) * self.noobject_scale\n",
    "        noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * self.noobject_scale\n",
    "\n",
    "        #coord_loss\n",
    "        coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(self.image_size/self.cell_size)) +\n",
    "                     tf.nn.l2_loss(I * (p_y - y)/(self.image_size/self.cell_size)) +\n",
    "                     tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/ self.image_size +\n",
    "                     tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/self.image_size) * self.coord_scale\n",
    "\n",
    "        nilboy = p_C\n",
    "\n",
    "        return (num + 1, object_num, [loss[0] + class_loss, \n",
    "                                      loss[1] + object_loss, \n",
    "                                      loss[2] + noobject_loss,\n",
    "                                      loss[3] + coord_loss], \n",
    "                predict, labels, nilboy)\n",
    "\n",
    "    def detect_from_cvmat(self,img):\n",
    "        s = time.time()\n",
    "        self.h_img,self.w_img,_ = img.shape\n",
    "        img_resized = cv2.resize(img, (448, 448))\n",
    "        img_RGB = cv2.cvtColor(img_resized,cv2.COLOR_BGR2RGB)\n",
    "        img_resized_np = np.asarray( img_RGB )\n",
    "        inputs = np.zeros((1,448,448,3),dtype='float32')\n",
    "        inputs[0] = (img_resized_np/255.0)*2.0-1.0\n",
    "        in_dict = {self.x: inputs}\n",
    "        net_output = self.sess.run(self.fc_32,feed_dict=in_dict)\n",
    "        self.result = self.interpret_output(net_output[0])\n",
    "        self.show_results(img,self.result)\n",
    "        strtime = str(time.time()-s)\n",
    "        if self.disp_console : print('Elapsed time : ' + strtime + ' secs' + '\\n')\n",
    "\n",
    "    def detect_from_file(self,filename):\n",
    "        if self.disp_console : print('Detect from ' + filename)\n",
    "        for i in range(len(filename)):\n",
    "            img = cv2.imread(filename)\n",
    "            self.detect_from_cvmat(img)\n",
    "\n",
    "    def detect_from_crop_sample(self):\n",
    "        self.w_img = 640\n",
    "        self.h_img = 420\n",
    "        f = np.array(open('person_crop.txt','r').readlines(),dtype='float32')\n",
    "        inputs = np.zeros((1,448,448,3),dtype='float32')\n",
    "        for c in range(3):\n",
    "            for y in range(448):\n",
    "                for x in range(448):\n",
    "                    inputs[0,y,x,c] = f[c*448*448+y*448+x]\n",
    "\n",
    "        in_dict = {self.x: inputs}\n",
    "        net_output = self.sess.run(self.fc_32,feed_dict=in_dict)\n",
    "        self.boxes, self.probs = self.interpret_output(net_output[0])\n",
    "        img = cv2.imread('person.jpg')\n",
    "        self.show_results(self.boxes,img)\n",
    "\n",
    "    def interpret_output(self,output):\n",
    "        probs = np.zeros((7,7,2,20))\n",
    "        class_probs = tf.reshape(output[0:980],(7,7,20))\n",
    "        scales = tf.reshape(output[980:1078],(7,7,2))\n",
    "        boxes = tf.reshape(output[1078:],(7,7,2,4))\n",
    "\n",
    "        offset = tf.transpose(np.reshape(np.array([np.arange(7)]*14),(2,7,7)),(1,2,0))\n",
    "        offset = tf.cast(offset, tf.float32)\n",
    "        \n",
    "        boxes[:,:,:,0] += offset\n",
    "        boxes[:,:,:,1] += np.transpose(offset,(1,0,2))\n",
    "        boxes[:,:,:,0:2] = boxes[:,:,:,0:2] / 7.0\n",
    "        boxes[:,:,:,2] = np.multiply(boxes[:,:,:,2],boxes[:,:,:,2])\n",
    "        boxes[:,:,:,3] = np.multiply(boxes[:,:,:,3],boxes[:,:,:,3])\n",
    "        \n",
    "        boxes[:,:,:,0] *= self.w_img\n",
    "        boxes[:,:,:,1] *= self.h_img\n",
    "        boxes[:,:,:,2] *= self.w_img\n",
    "        boxes[:,:,:,3] *= self.h_img\n",
    "\n",
    "        for i in range(2):\n",
    "            for j in range(20):\n",
    "                probs[:,:,i,j] = np.multiply(class_probs[:,:,j],scales[:,:,i])\n",
    "\n",
    "        filter_mat_probs = np.array(probs>=self.threshold,dtype='bool')\n",
    "        filter_mat_boxes = np.nonzero(filter_mat_probs)\n",
    "        boxes_filtered = boxes[filter_mat_boxes[0],filter_mat_boxes[1],filter_mat_boxes[2]]\n",
    "        probs_filtered = probs[filter_mat_probs]\n",
    "        classes_num_filtered = np.argmax(filter_mat_probs,axis=3)[filter_mat_boxes[0],filter_mat_boxes[1],filter_mat_boxes[2]] \n",
    "\n",
    "        argsort = np.array(np.argsort(probs_filtered))[::-1]\n",
    "        boxes_filtered = boxes_filtered[argsort]\n",
    "        probs_filtered = probs_filtered[argsort]\n",
    "        classes_num_filtered = classes_num_filtered[argsort]\n",
    "        \n",
    "        for i in range(len(boxes_filtered)):\n",
    "            if probs_filtered[i] == 0 : continue\n",
    "            for j in range(i+1,len(boxes_filtered)):\n",
    "                if self.iou(boxes_filtered[i],boxes_filtered[j]) > self.iou_threshold : \n",
    "                    probs_filtered[j] = 0.0\n",
    "        \n",
    "        filter_iou = np.array(probs_filtered>0.0,dtype='bool')\n",
    "        boxes_filtered = boxes_filtered[filter_iou]\n",
    "        probs_filtered = probs_filtered[filter_iou]\n",
    "        classes_num_filtered = classes_num_filtered[filter_iou]\n",
    "\n",
    "        result = []\n",
    "        for i in range(len(boxes_filtered)):\n",
    "            result.append([self.classes[classes_num_filtered[i]],boxes_filtered[i][0],boxes_filtered[i][1],boxes_filtered[i][2],boxes_filtered[i][3],probs_filtered[i]])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def show_results(self,img,results):\n",
    "        img_cp = img.copy()\n",
    "        if self.filewrite_txt :\n",
    "            ftxt = open(self.tofile_txt,'w')\n",
    "        for i in range(len(results)):\n",
    "            x = int(results[i][1])\n",
    "            y = int(results[i][2])\n",
    "            w = int(results[i][3])//2\n",
    "            h = int(results[i][4])//2\n",
    "            if self.disp_console : print('    class : ' + results[i][0] + ' , [x,y,w,h]=[' + str(x) + ',' + str(y) + ',' + str(int(results[i][3])) + ',' + str(int(results[i][4]))+'], Confidence = ' + str(results[i][5]))\n",
    "            if self.filewrite_img or self.imshow:\n",
    "                cv2.rectangle(img_cp,(x-w,y-h),(x+w,y+h),(0,255,0),2)\n",
    "                cv2.rectangle(img_cp,(x-w,y-h-20),(x+w,y-h),(125,125,125),-1)\n",
    "                cv2.putText(img_cp,results[i][0] + ' : %.2f' % results[i][5],(x-w+5,y-h-7),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1)\n",
    "            if self.filewrite_txt :             \n",
    "                ftxt.write(results[i][0] + ',' + str(x) + ',' + str(y) + ',' + str(w) + ',' + str(h)+',' + str(results[i][5]) + '\\n')\n",
    "        if self.filewrite_img : \n",
    "            if self.disp_console : print('    image file writed : ' + self.tofile_img)\n",
    "            cv2.imwrite(self.tofile_img,img_cp)         \n",
    "        if self.imshow :\n",
    "            cv2.imshow('YOLO_small detection',img_cp)\n",
    "            cv2.waitKey(1)\n",
    "        if self.filewrite_txt : \n",
    "            if self.disp_console : print('    txt file writed : ' + self.tofile_txt)\n",
    "            ftxt.close()\n",
    "\n",
    "    def iou(self, boxes1, boxes2):\n",
    "        \"\"\"calculate ious\n",
    "        Args:\n",
    "          boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "          boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "          \n",
    "        Return:\n",
    "          iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        \"\"\"\n",
    "        \n",
    "        #boxes1 : [4(xmin, ymin, xmax, ymax), cell_size, cell_size, boxes_per_cell]\n",
    "        boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                          boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "        \n",
    "        #boxes1 : [cell_size, cell_size, boxes_per_cell, 4(xmin, ymin, xmax, ymax)]\n",
    "        boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "\n",
    "        boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                          boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "\n",
    "        #calculate the left up point of boxes' overlap area\n",
    "        lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "        #calculate the right down point of boxes overlap area\n",
    "        rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "\n",
    "        #intersection\n",
    "        intersection = rd - lu \n",
    "\n",
    "        #the size of the intersection area\n",
    "        inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "        \n",
    "        mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "\n",
    "        #if intersection is negative, then the boxes don't overlap\n",
    "        inter_square = mask * inter_square\n",
    "\n",
    "        #calculate the boxs1 square and boxs2 square\n",
    "        square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "        square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "\n",
    "        return inter_square/(square1 + square2 - inter_square + 1e-6)\n",
    "def main(argvs):\n",
    "    yolo = YOLO_TF(argvs)\n",
    "    # cv2.waitKey(1000)\n",
    "    yolo.training()\n",
    "\n",
    "\n",
    "if __name__=='__main__':    \n",
    "    main(sys.argv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # python small_demo.py -fromfile './cat.jpg'\n",
    "version = 14000\n",
    "version = str(version)\n",
    "evaluate_name = 'new'+version+'.ckpt'\n",
    "fuji_mode = 'pascal'\n",
    "thre = [0,2,4]\n",
    "# fuji_mode = '000004.jpg'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class YOLO_TF:\n",
    "    fromfile = None\n",
    "    tofile_img = 'test/output.jpg'\n",
    "    tofile_txt = 'test/output.txt'\n",
    "    imshow = True\n",
    "    filewrite_img = False\n",
    "    filewrite_txt = False\n",
    "    disp_console = True\n",
    "    weights_file = 'models/train/'+evaluate_name\n",
    "    \n",
    "    alpha = 0.1\n",
    "    threshold = 0.12\n",
    "    num_classes = 20\n",
    "    iou_threshold = 0.5\n",
    "    boxes_per_cell = 2\n",
    "    cell_size = 7\n",
    "    classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "    img_dir = '/media/labhdd/VOCdevkit/VOC2007/JPEGImages/'\n",
    "    w_img = 0\n",
    "    h_img = 0\n",
    "    max_boxs = 20\n",
    "\n",
    "    def __init__(self,argvs = []):\n",
    "        self.build_networks()\n",
    "        if fuji_mode == 'pascal':\n",
    "            self.fromfile = self.get_files_path()\n",
    "            self.detect_and_write(self.fromfile)\n",
    "        else:\n",
    "            self.detect_from_file(fuji_mode)\n",
    "        \n",
    "    def get_files_path(self):\n",
    "        test_img_files = open('pascal_voc_testing_data.txt')\n",
    "        test_images = []\n",
    "        import numpy as np\n",
    "        for line in test_img_files:\n",
    "            line = line.strip()\n",
    "            ss = line.split(' ')\n",
    "            test_images.append(ss[0])\n",
    "        return test_images\n",
    "    def interpret_output(self,output):\n",
    "        probs = np.zeros((7,7,2,20))\n",
    "        class_probs = np.reshape(output[0:980],(7,7,20))\n",
    "        scales = np.reshape(output[980:1078],(7,7,2))\n",
    "        boxes = np.reshape(output[1078:],(7,7,2,4))\n",
    "        offset = np.transpose(np.reshape(np.array([np.arange(7)]*14),(2,7,7)),(1,2,0))\n",
    "\n",
    "        boxes[:,:,:,0] += offset\n",
    "        boxes[:,:,:,1] += np.transpose(offset,(1,0,2))\n",
    "        boxes[:,:,:,0:2] = boxes[:,:,:,0:2] / 7.0\n",
    "        boxes[:,:,:,2] = np.multiply(boxes[:,:,:,2],boxes[:,:,:,2])\n",
    "        boxes[:,:,:,3] = np.multiply(boxes[:,:,:,3],boxes[:,:,:,3])\n",
    "        \n",
    "        boxes[:,:,:,0] *= self.w_img\n",
    "        boxes[:,:,:,1] *= self.h_img\n",
    "        boxes[:,:,:,2] *= self.w_img\n",
    "        boxes[:,:,:,3] *= self.h_img\n",
    "\n",
    "        for i in range(2):\n",
    "            for j in range(20):\n",
    "                probs[:,:,i,j] = np.multiply(class_probs[:,:,j],scales[:,:,i])\n",
    "\n",
    "        filter_mat_probs = np.array(probs>=self.threshold,dtype='bool')\n",
    "        filter_mat_boxes = np.nonzero(filter_mat_probs)\n",
    "        boxes_filtered = boxes[filter_mat_boxes[0],filter_mat_boxes[1],filter_mat_boxes[2]]\n",
    "        probs_filtered = probs[filter_mat_probs]\n",
    "        classes_num_filtered = np.argmax(filter_mat_probs,axis=3)[filter_mat_boxes[0],filter_mat_boxes[1],filter_mat_boxes[2]] \n",
    "\n",
    "        argsort = np.array(np.argsort(probs_filtered))[::-1]\n",
    "        boxes_filtered = boxes_filtered[argsort]\n",
    "        probs_filtered = probs_filtered[argsort]\n",
    "        classes_num_filtered = classes_num_filtered[argsort]\n",
    "        \n",
    "        for i in range(len(boxes_filtered)):\n",
    "            if probs_filtered[i] == 0 : continue\n",
    "            for j in range(i+1,len(boxes_filtered)):\n",
    "                if self.iou(boxes_filtered[i],boxes_filtered[j]) > self.iou_threshold : \n",
    "                    probs_filtered[j] = 0.0\n",
    "        \n",
    "        filter_iou = np.array(probs_filtered>0.0,dtype='bool')\n",
    "        boxes_filtered = boxes_filtered[filter_iou] #xywh\n",
    "        probs_filtered = probs_filtered[filter_iou]\n",
    "        classes_num_filtered = classes_num_filtered[filter_iou]\n",
    "\n",
    "        result = []\n",
    "        for i in range(len(boxes_filtered)):\n",
    "            result.append([self.classes_name[classes_num_filtered[i]],boxes_filtered[i][0],boxes_filtered[i][1],boxes_filtered[i][2],boxes_filtered[i][3],probs_filtered[i]])\n",
    "\n",
    "        return result\n",
    "    def iou(self,box1,box2):\n",
    "        tb = min(box1[0]+0.5*box1[2],box2[0]+0.5*box2[2])-max(box1[0]-0.5*box1[2],box2[0]-0.5*box2[2])\n",
    "        lr = min(box1[1]+0.5*box1[3],box2[1]+0.5*box2[3])-max(box1[1]-0.5*box1[3],box2[1]-0.5*box2[3])\n",
    "        if tb < 0 or lr < 0 : intersection = 0\n",
    "        else : intersection =  tb*lr\n",
    "        return intersection / (box1[2]*box1[3] + box2[2]*box2[3] - intersection)\n",
    "    def build_networks(self):\n",
    "        if self.disp_console : print(\"Building YOLO_small graph...\")\n",
    "        self.x = tf.placeholder('float32',[None,448,448,3])\n",
    "        self.conv_1 = self.conv_layer(1,self.x,64,7,2)\n",
    "        self.pool_2 = self.pooling_layer(2,self.conv_1,2,2)\n",
    "        self.conv_3 = self.conv_layer(3,self.pool_2,192,3,1)\n",
    "        self.pool_4 = self.pooling_layer(4,self.conv_3,2,2)\n",
    "        self.conv_5 = self.conv_layer(5,self.pool_4,128,1,1)\n",
    "        self.conv_6 = self.conv_layer(6,self.conv_5,256,3,1)\n",
    "        self.conv_7 = self.conv_layer(7,self.conv_6,256,1,1)\n",
    "        self.conv_8 = self.conv_layer(8,self.conv_7,512,3,1)\n",
    "        self.pool_9 = self.pooling_layer(9,self.conv_8,2,2)\n",
    "        self.conv_10 = self.conv_layer(10,self.pool_9,256,1,1)\n",
    "        self.conv_11 = self.conv_layer(11,self.conv_10,512,3,1)\n",
    "        self.conv_12 = self.conv_layer(12,self.conv_11,256,1,1)\n",
    "        self.conv_13 = self.conv_layer(13,self.conv_12,512,3,1)\n",
    "        self.conv_14 = self.conv_layer(14,self.conv_13,256,1,1)\n",
    "        self.conv_15 = self.conv_layer(15,self.conv_14,512,3,1)\n",
    "        self.conv_16 = self.conv_layer(16,self.conv_15,256,1,1)\n",
    "        self.conv_17 = self.conv_layer(17,self.conv_16,512,3,1)\n",
    "        self.conv_18 = self.conv_layer(18,self.conv_17,512,1,1)\n",
    "        self.conv_19 = self.conv_layer(19,self.conv_18,1024,3,1)\n",
    "        self.pool_20 = self.pooling_layer(20,self.conv_19,2,2)\n",
    "        self.conv_21 = self.conv_layer(21,self.pool_20,512,1,1)\n",
    "        self.conv_22 = self.conv_layer(22,self.conv_21,1024,3,1)\n",
    "        self.conv_23 = self.conv_layer(23,self.conv_22,512,1,1)\n",
    "        self.conv_24 = self.conv_layer(24,self.conv_23,1024,3,1)\n",
    "        self.conv_25 = self.conv_layer(25,self.conv_24,1024,3,1)\n",
    "        self.conv_26 = self.conv_layer(26,self.conv_25,1024,3,2)\n",
    "        self.conv_27 = self.conv_layer(27,self.conv_26,1024,3,1)\n",
    "        self.conv_28 = self.conv_layer(28,self.conv_27,1024,3,1)\n",
    "        self.fc_29 = self.fc_layer(29,self.conv_28,512,flat=True,linear=False)\n",
    "        self.fc_30 = self.fc_layer(30,self.fc_29,4096,flat=False,linear=False)\n",
    "        #skip dropout_31\n",
    "        self.fc_32 = self.fc_layer(32,self.fc_30,1470,flat=False,linear=True)\n",
    "\n",
    "        n1 = self.cell_size * self.cell_size * self.num_classes\n",
    "        n2 = n1 + self.cell_size * self.cell_size * self.boxes_per_cell\n",
    "        class_probs = tf.reshape(self.fc_32[:, 0:n1], (-1, 7,7,20))\n",
    "        scales = tf.reshape(self.fc_32[:, n1:n2], (-1, 7,7,2))\n",
    "        boxes = tf.reshape(self.fc_32[:, n2:], (-1,7, 7, 2*4))\n",
    "       \n",
    "        self.predicts   = tf.concat([class_probs, scales, boxes], 3)\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.initialize_all_variables())\n",
    "        self.saver = tf.train.Saver()\n",
    "        # self.saver = tf.train.import_meta_graph(self.weights_file+'.meta')\n",
    "        self.saver.restore(self.sess, self.weights_file)\n",
    "        if self.disp_console : print(\"Loading complete!\" + '\\n')\n",
    "\n",
    "    def conv_layer(self,idx,inputs,filters,size,stride):\n",
    "        channels = inputs.get_shape()[3]\n",
    "        weight = tf.Variable(tf.truncated_normal([size,size,int(channels),filters], stddev=0.1))\n",
    "        biases = tf.Variable(tf.constant(0.1, shape=[filters]))\n",
    "\n",
    "        pad_size = size//2\n",
    "        pad_mat = np.array([[0,0],[pad_size,pad_size],[pad_size,pad_size],[0,0]])\n",
    "        inputs_pad = tf.pad(inputs,pad_mat)\n",
    "\n",
    "        conv = tf.nn.conv2d(inputs_pad, weight, strides=[1, stride, stride, 1], padding='VALID',name=str(idx)+'_conv')  \n",
    "        conv_biased = tf.add(conv,biases,name=str(idx)+'_conv_biased')  \n",
    "        if self.disp_console : print('    Layer  %d : Type = Conv, Size = %d * %d, Stride = %d, Filters = %d, Input channels = %d' % (idx,size,size,stride,filters,int(channels)))\n",
    "        return tf.maximum(self.alpha*conv_biased,conv_biased,name=str(idx)+'_leaky_relu')\n",
    "\n",
    "    def pooling_layer(self,idx,inputs,size,stride):\n",
    "        if self.disp_console : print('    Layer  %d : Type = Pool, Size = %d * %d, Stride = %d' % (idx,size,size,stride))\n",
    "        return tf.nn.max_pool(inputs, ksize=[1, size, size, 1],strides=[1, stride, stride, 1], padding='SAME',name=str(idx)+'_pool')\n",
    "\n",
    "    def fc_layer(self,idx,inputs,hiddens,flat = False,linear = False):\n",
    "        input_shape = inputs.get_shape().as_list()      \n",
    "        if flat:\n",
    "            dim = input_shape[1]*input_shape[2]*input_shape[3]\n",
    "            inputs_transposed = tf.transpose(inputs,(0,3,1,2))\n",
    "            inputs_processed = tf.reshape(inputs_transposed, [-1,dim])\n",
    "        else:\n",
    "            dim = input_shape[1]\n",
    "            inputs_processed = inputs\n",
    "        weight = tf.Variable(tf.truncated_normal([dim,hiddens], stddev=0.1))\n",
    "        biases = tf.Variable(tf.constant(0.1, shape=[hiddens])) \n",
    "        if self.disp_console : print('    Layer  %d : Type = Full, Hidden = %d, Input dimension = %d, Flat = %d, Activation = %d' % (idx,hiddens,int(dim),int(flat),1-int(linear))  )\n",
    "        if linear : return tf.add(tf.matmul(inputs_processed,weight),biases,name=str(idx)+'_fc')\n",
    "        ip = tf.add(tf.matmul(inputs_processed,weight),biases)\n",
    "        return tf.maximum(self.alpha*ip,ip,name=str(idx)+'_fc')\n",
    "    def detect_from_file(self,filename):\n",
    "        if self.disp_console : print('Detect from ' + filename)\n",
    "        for i in range(1):\n",
    "            img = cv2.imread(filename)\n",
    "            self.detect_from_cvmat(img)\n",
    "    def detect_and_write(self,file_lst):\n",
    "       \n",
    "        all_pred = []\n",
    "        for name in file_lst:\n",
    "            pred20 = []\n",
    "            print('predict ',name)\n",
    "            np_img = cv2.imread(self.img_dir+name)\n",
    "            if np_img is None:\n",
    "                raise Exception('load err:path not found',self.img_dir+name)\n",
    "            img = np_img.copy()\n",
    "            self.h_img,self.w_img,_ = img.shape\n",
    "            \n",
    "            resized_img = cv2.resize(np_img, (448, 448))\n",
    "            np_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "            np_img = np_img.astype(np.float32)\n",
    "            np_img = np.reshape(np_img, (1, 448, 448, 3))\n",
    "            np_img = np_img / 255.0 * 2 - 1\n",
    "\n",
    "            np_predict = self.sess.run(self.predicts, feed_dict={self.x: np_img})\n",
    "            xmin, ymin, xmax, ymax, classes_num,conf = self.process_predicts(np_predict)\n",
    "                \n",
    "            for i in range(len(xmin)):\n",
    "                if (0<=xmin[i]<= self.w_img) and (0<=xmax[i]<= self.w_img) and (0<=ymin[i]<= self.h_img) and (0<=ymax[i]<= self.h_img):\n",
    "                    pred20.append([int(xmin[i]),int(ymin[i]),int(xmax[i]),int(ymax[i]),classes_num[i],conf[i]])\n",
    "            all_pred.append(pred20)\n",
    "\n",
    "        with open('./out/'+version+'_'+str(thre[0])+'.txt','w') as f1,open('./out/'+version+'_'+str(thre[1])+'.txt','w') as f2,open('./out/'+version+'_'+str(thre[2])+'.txt','w') as f3:\n",
    "            for imgidx,name in enumerate(file_lst):\n",
    "                f1.write(name)\n",
    "                f2.write(name)\n",
    "                f3.write(name)\n",
    "                for i in range(20):\n",
    "                    xmin, ymin, xmax, ymax, classes_num,conf=all_pred[imgidx][i]\n",
    "                    if i != 0:\n",
    "                        if conf > (thre[0]*0.01):\n",
    "                            f1.write(\" %s %s %s %s %s %s\" %(int(xmin),int(ymin),int(xmax),int(ymax),classes_num,conf))\n",
    "                        else:\n",
    "                            break\n",
    "                        if conf > (thre[1]*0.01):\n",
    "                            f2.write(\" %s %s %s %s %s %s\" %(int(xmin),int(ymin),int(xmax),int(ymax),classes_num,conf))\n",
    "                        if conf > (thre[2]*0.01):\n",
    "                            f3.write(\" %s %s %s %s %s %s\" %(int(xmin),int(ymin),int(xmax),int(ymax),classes_num,conf))\n",
    "\n",
    "                    else:\n",
    "                        f1.write(\" %s %s %s %s %s %s\" %(int(xmin),int(ymin),int(xmax),int(ymax),classes_num,conf))\n",
    "                        f2.write(\" %s %s %s %s %s %s\" %(int(xmin),int(ymin),int(xmax),int(ymax),classes_num,conf))\n",
    "                        f3.write(\" %s %s %s %s %s %s\" %(int(xmin),int(ymin),int(xmax),int(ymax),classes_num,conf))\n",
    "                f1.write(\"\\n\")\n",
    "                f2.write(\"\\n\")\n",
    "                f3.write(\"\\n\")\n",
    "                \n",
    "    def detect_from_cvmat(self,np_img):\n",
    "        s = time.time()\n",
    "\n",
    "        img = np_img.copy()\n",
    "        self.h_img,self.w_img,_ = img.shape\n",
    "        \n",
    "        resized_img = cv2.resize(np_img, (448, 448))\n",
    "        np_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "        np_img = np_img.astype(np.float32)\n",
    "        np_img = np.reshape(np_img, (1, 448, 448, 3))\n",
    "        np_img = np_img / 255.0 * 2 - 1\n",
    "        \n",
    "        np_predict = self.sess.run(self.predicts, feed_dict={self.x: np_img})\n",
    "        fc_out = self.sess.run(self.fc_32, feed_dict={self.x: np_img})\n",
    "        result = self.interpret_output(fc_out[0])\n",
    "        self.out_ori_img(img,result)\n",
    "\n",
    "        # print(result)\n",
    "        # [x,y,w,h] = result[0][1:-1]\n",
    "        # print('small:',x,y,x+w,y+h)\n",
    "\n",
    "        # print(np_predict.shape)#(1,7,7,30)\n",
    "        xmin, ymin, xmax, ymax, classes_num,conf = self.process_predicts(np_predict)\n",
    "\n",
    "        \n",
    "        # xmin_, ymin_, xmax_, ymax_, classes_num_,conf_ = self.process_predicts_TA(np_predict)\n",
    "        # print('TA:',xmin_, ymin_, xmax_, ymax_)\n",
    "        \n",
    "        for i in range(len(xmin)):\n",
    "            print('nilboy:',xmin[i], ymin[i], xmax[i], ymax[i],self.classes_name[int(classes_num[i])],conf[i])\n",
    "            class_name = self.classes_name[classes_num[i]]\n",
    "            cv2.rectangle(img, (int(xmin[i]), int(ymin[i])), (int(xmax[i]), int(ymax[i])), (0, 0, 255))\n",
    "            # cv2.putText(resized_img, class_name, (int(xmin[i]), int(ymin[i])), 2, 1.5, (0, 0, 255))\n",
    "            cv2.putText(img,class_name,(int(xmin[i]), int(ymin[i])),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),1)\n",
    "            cv2.putText(img,str(conf[i]),(int(xmin[i]), int(ymin[i])+30),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),1)\n",
    "            \n",
    "        cv2.imshow('YOLO_small detection',resized_img)\n",
    "        cv2.imwrite('out.jpg', img)\n",
    "        # cv2.waitKey(10000)\n",
    "    def out_ori_img(self,img,results):\n",
    "        img_cp = img.copy()\n",
    "\n",
    "        for i in range(len(results)):\n",
    "            x = int(results[i][1])\n",
    "            y = int(results[i][2])\n",
    "            w = int(results[i][3])//2\n",
    "            h = int(results[i][4])//2\n",
    "            cv2.rectangle(img_cp,(x-w,y-h),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.rectangle(img_cp,(x-w,y-h-20),(x+w,y-h),(125,125,125),-1)\n",
    "            cv2.putText(img_cp,results[i][0] + ' : %.2f' % results[i][5],(x-w+5,y-h-7),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1)\n",
    "\n",
    "        cv2.imwrite('./ori_cat.jpg',img_cp)         \n",
    "\n",
    "\n",
    "    def process_predicts(self,predicts):\n",
    "        # probs = np.zeros((7,7,2,20))\n",
    "        # class_probs = np.reshape(output[0:980],(7,7,20))\n",
    "        # scales = np.reshape(output[980:1078],(7,7,2))\n",
    "        # boxes = np.reshape(output[1078:],(7,7,2,4))\n",
    "        # offset = np.transpose(np.reshape(np.array([np.arange(7)]*14),(2,7,7)),(1,2,0))\n",
    "\n",
    "        p_classes = predicts[0, :, :, 0:20]\n",
    "        C = predicts[0, :, :, 20:22]\n",
    "        coordinate = predicts[0, :, :, 22:]\n",
    "\n",
    "        p_classes = np.reshape(p_classes, (7, 7, 1, 20))\n",
    "        C = np.reshape(C, (7, 7, 2, 1))\n",
    "\n",
    "        P = C * p_classes\n",
    "        xmin =[]\n",
    "        ymin = []\n",
    "\n",
    "        xmax = []\n",
    "        ymax = []\n",
    "        class_num = []\n",
    "        conf = []\n",
    "        Psort = np.argsort(P.flatten())\n",
    "        cur_thres = self.threshold\n",
    "        for i in range(self.max_boxs):\n",
    "            index = Psort[-(i+1)]\n",
    "            tmp_conf = P.flatten()[index]\n",
    "            # if index[3] == 4: #bottle\n",
    "            #     tmp_conf *=10\n",
    "            #out put at least one box is important\n",
    "            # if tmp_conf < cur_thres and (i != 0):\n",
    "            #     break\n",
    "\n",
    "            index = np.unravel_index(index, P.shape)\n",
    "            \n",
    "\n",
    "            class_num.append(index[3])\n",
    "\n",
    "            coordinate = np.reshape(coordinate, (7, 7, 2, 4))\n",
    "\n",
    "            max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "            xcenter = max_coordinate[0]\n",
    "            ycenter = max_coordinate[1]\n",
    "            w = max_coordinate[2]\n",
    "            h = max_coordinate[3]\n",
    "\n",
    "            xcenter = (index[1] + xcenter) * (448/7.0)\n",
    "            ycenter = (index[0] + ycenter) * (448/7.0)\n",
    "\n",
    "            w = w * 448\n",
    "            h = h * 448\n",
    "            xmin_tmp = xcenter - w/2.0\n",
    "            ymin_tmp = ycenter - h/2.0\n",
    "\n",
    "            xmin.append(xmin_tmp)\n",
    "            ymin.append(ymin_tmp)\n",
    "            xmax.append(xmin_tmp + w)\n",
    "            ymax.append(ymin_tmp + h)\n",
    "            conf.append(tmp_conf)\n",
    "\n",
    "        xmin = np.array(xmin)\n",
    "        ymin = np.array(ymin)\n",
    "        xmax = np.array(xmax)\n",
    "        ymax = np.array(ymax)\n",
    "        \n",
    "        xmin *= (self.w_img/448.0)\n",
    "        ymin *= (self.h_img/448.0)\n",
    "        xmax *= (self.w_img/448.0)\n",
    "        ymax *= (self.h_img/448.0)\n",
    "\n",
    "        xmin = np.clip(xmin, 0, self.w_img-1)\n",
    "        ymin = np.clip(ymin, 0, self.h_img-1)\n",
    "        xmax = np.clip(xmax, 0, self.w_img-1)\n",
    "        ymax = np.clip(ymax, 0, self.h_img-1)\n",
    "        \n",
    "        return xmin, ymin, xmax, ymax, class_num,conf\n",
    "        \n",
    "  \n",
    "yolo = YOLO_TF()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"DataSet  base class \n",
    "\"\"\"\n",
    "class DataSet(object):\n",
    "  \"\"\"Base DataSet\n",
    "  \"\"\"\n",
    "  def __init__(self, common_params, dataset_params):\n",
    "    \"\"\"\n",
    "    common_params: A params dict \n",
    "    dataset_params: A params dict\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def batch(self):\n",
    "    \"\"\"Get batch\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from queue import Queue \n",
    "from threading import Thread\n",
    "\n",
    "from yolo.dataset.dataset import DataSet \n",
    "\n",
    "class TextDataSet(DataSet):\n",
    "  \"\"\"TextDataSet\n",
    "  process text input file dataset \n",
    "  text file format:\n",
    "    image_path xmin1 ymin1 xmax1 ymax1 class1 xmin2 ymin2 xmax2 ymax2 class2\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, common_params, dataset_params):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      common_params: A dict\n",
    "      dataset_params: A dict\n",
    "    \"\"\"\n",
    "    #process params\n",
    "    self.data_path = str(dataset_params['path'])\n",
    "    self.width = int(common_params['image_size'])\n",
    "    self.height = int(common_params['image_size'])\n",
    "    self.batch_size = int(common_params['batch_size'])\n",
    "    self.thread_num = int(dataset_params['thread_num'])\n",
    "    self.max_objects = int(common_params['max_objects_per_image'])\n",
    "\n",
    "    #record and image_label queue\n",
    "    self.record_queue = Queue(maxsize=10000)\n",
    "    self.image_label_queue = Queue(maxsize=512)\n",
    "\n",
    "    self.record_list = []  \n",
    "\n",
    "    # filling the record_list\n",
    "    input_file = open(self.data_path, 'r')\n",
    "\n",
    "    for line in input_file:\n",
    "      line = line.strip()\n",
    "      ss = line.split(' ')\n",
    "      ss[1:] = [float(num) for num in ss[1:]]\n",
    "      self.record_list.append(ss)\n",
    "\n",
    "    self.record_point = 0\n",
    "    self.record_number = len(self.record_list)\n",
    "\n",
    "    self.num_batch_per_epoch = int(self.record_number / self.batch_size)\n",
    "\n",
    "    t_record_producer = Thread(target=self.record_producer)\n",
    "    t_record_producer.daemon = True \n",
    "    t_record_producer.start()\n",
    "\n",
    "    for i in range(self.thread_num):\n",
    "      t = Thread(target=self.record_customer)\n",
    "      t.daemon = True\n",
    "      t.start() \n",
    "\n",
    "  def record_producer(self):\n",
    "    \"\"\"record_queue's processor\n",
    "    \"\"\"\n",
    "    while True:\n",
    "      if self.record_point % self.record_number == 0:\n",
    "        random.shuffle(self.record_list)\n",
    "        self.record_point = 0\n",
    "      self.record_queue.put(self.record_list[self.record_point])\n",
    "      self.record_point += 1\n",
    "\n",
    "  def record_process(self, record):\n",
    "    \"\"\"record process \n",
    "    Args: record \n",
    "    Returns:\n",
    "      image: 3-D ndarray\n",
    "      labels: 2-D list [self.max_objects, 5] (xcenter, ycenter, w, h, class_num)\n",
    "      object_num:  total object number  int \n",
    "    \"\"\"\n",
    "    image = cv2.imread(record[0])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "\n",
    "    width_rate = self.width * 1.0 / w \n",
    "    height_rate = self.height * 1.0 / h \n",
    "\n",
    "    image = cv2.resize(image, (self.height, self.width))\n",
    "\n",
    "    labels = [[0, 0, 0, 0, 0]] * self.max_objects\n",
    "    i = 1\n",
    "    object_num = 0\n",
    "    while i < len(record):\n",
    "      xmin = record[i]\n",
    "      ymin = record[i + 1]\n",
    "      xmax = record[i + 2]\n",
    "      ymax = record[i + 3]\n",
    "      class_num = record[i + 4]\n",
    "\n",
    "      xcenter = (xmin + xmax) * 1.0 / 2 * width_rate\n",
    "      ycenter = (ymin + ymax) * 1.0 / 2 * height_rate\n",
    "\n",
    "      box_w = (xmax - xmin) * width_rate\n",
    "      box_h = (ymax - ymin) * height_rate\n",
    "\n",
    "      labels[object_num] = [xcenter, ycenter, box_w, box_h, class_num]\n",
    "      object_num += 1\n",
    "      i += 5\n",
    "      if object_num >= self.max_objects:\n",
    "        break\n",
    "    return [image, labels, object_num]\n",
    "\n",
    "  def record_customer(self):\n",
    "    \"\"\"record queue's customer \n",
    "    \"\"\"\n",
    "    while True:\n",
    "      item = self.record_queue.get()\n",
    "      out = self.record_process(item)\n",
    "      self.image_label_queue.put(out)\n",
    "\n",
    "  def batch(self):\n",
    "    \"\"\"get batch\n",
    "    Returns:\n",
    "      images: 4-D ndarray [batch_size, height, width, 3]\n",
    "      labels: 3-D ndarray [batch_size, max_objects, 5]\n",
    "      objects_num: 1-D ndarray [batch_size]\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    objects_num = []\n",
    "    for i in range(self.batch_size):\n",
    "      image, label, object_num = self.image_label_queue.get()\n",
    "      images.append(image)\n",
    "      labels.append(label)\n",
    "      objects_num.append(object_num)\n",
    "    images = np.asarray(images, dtype=np.float32)\n",
    "    images = images/255 * 2 - 1\n",
    "    labels = np.asarray(labels, dtype=np.float32)\n",
    "    objects_num = np.asarray(objects_num, dtype=np.int32)\n",
    "    return images, labels, objects_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[Common]\n",
    "image_size: 448\n",
    "batch_size: 16\n",
    "num_classes: 20\n",
    "max_objects_per_image: 20\n",
    "[DataSet]\n",
    "name: yolo.dataset.text_dataset.TextDataSet\n",
    "path: data/pascal_voc_train.txt\n",
    "thread_num: 5\n",
    "[Net]\n",
    "weight_decay: 0.0005\n",
    "cell_size: 7\n",
    "boxes_per_cell: 2\n",
    "object_scale: 1\n",
    "noobject_scale: 0.5\n",
    "class_scale: 1\n",
    "coord_scale: 5\n",
    "[Solver]\n",
    "learning_rate: 0.0000007\n",
    "moment: 0.09\n",
    "max_iterators: 150010\n",
    "train_dir: models/train\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
